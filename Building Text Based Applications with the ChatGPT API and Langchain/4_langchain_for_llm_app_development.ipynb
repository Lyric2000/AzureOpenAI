{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docarray\n",
      "  Obtaining dependency information for docarray from https://files.pythonhosted.org/packages/fb/36/f671fa88de3d1cfb59cbc02659a13680f16fc0e9f6495453a068735baccd/docarray-0.37.1-py3-none-any.whl.metadata\n",
      "  Downloading docarray-0.37.1-py3-none-any.whl.metadata (36 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/mykielee/GitHub/oreilly_live_training_llm_apps/oreilly_env/lib/python3.9/site-packages (from docarray) (1.25.2)\n",
      "Collecting orjson>=3.8.2 (from docarray)\n",
      "  Obtaining dependency information for orjson>=3.8.2 from https://files.pythonhosted.org/packages/bc/57/17e518de07d0e2cae06259dd1676f589bc8873f1151b874b9e9d50cdbb13/orjson-3.9.5-cp39-cp39-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata\n",
      "  Using cached orjson-3.9.5-cp39-cp39-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (49 kB)\n",
      "Requirement already satisfied: pydantic<2.0.0,>=1.10.2 in /Users/mykielee/GitHub/oreilly_live_training_llm_apps/oreilly_env/lib/python3.9/site-packages (from docarray) (1.10.12)\n",
      "Collecting rich>=13.1.0 (from docarray)\n",
      "  Obtaining dependency information for rich>=13.1.0 from https://files.pythonhosted.org/packages/8d/5f/21a93b2ec205f4b79853ff6e838e3c99064d5dbe85ec6b05967506f14af0/rich-13.5.2-py3-none-any.whl.metadata\n",
      "  Using cached rich-13.5.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting types-requests>=2.28.11.6 (from docarray)\n",
      "  Obtaining dependency information for types-requests>=2.28.11.6 from https://files.pythonhosted.org/packages/06/9b/04bb62f11a6824df5d4568439cf0715118c265d0ffbebeb7cf4b8c9caa15/types_requests-2.31.0.2-py3-none-any.whl.metadata\n",
      "  Using cached types_requests-2.31.0.2-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/mykielee/GitHub/oreilly_live_training_llm_apps/oreilly_env/lib/python3.9/site-packages (from docarray) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/mykielee/GitHub/oreilly_live_training_llm_apps/oreilly_env/lib/python3.9/site-packages (from pydantic<2.0.0,>=1.10.2->docarray) (4.7.1)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13.1.0->docarray)\n",
      "  Obtaining dependency information for markdown-it-py>=2.2.0 from https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl.metadata\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/mykielee/GitHub/oreilly_live_training_llm_apps/oreilly_env/lib/python3.9/site-packages (from rich>=13.1.0->docarray) (2.16.1)\n",
      "Collecting types-urllib3 (from types-requests>=2.28.11.6->docarray)\n",
      "  Obtaining dependency information for types-urllib3 from https://files.pythonhosted.org/packages/11/7b/3fc711b2efea5e85a7a0bbfe269ea944aa767bbba5ec52f9ee45d362ccf3/types_urllib3-1.26.25.14-py3-none-any.whl.metadata\n",
      "  Using cached types_urllib3-1.26.25.14-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/mykielee/GitHub/oreilly_live_training_llm_apps/oreilly_env/lib/python3.9/site-packages (from typing-inspect>=0.8.0->docarray) (1.0.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading docarray-0.37.1-py3-none-any.whl (263 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.7/263.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached orjson-3.9.5-cp39-cp39-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (243 kB)\n",
      "Using cached rich-13.5.2-py3-none-any.whl (239 kB)\n",
      "Using cached types_requests-2.31.0.2-py3-none-any.whl (14 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached types_urllib3-1.26.25.14-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: types-urllib3, types-requests, orjson, mdurl, markdown-it-py, rich, docarray\n",
      "Successfully installed docarray-0.37.1 markdown-it-py-3.0.0 mdurl-0.1.2 orjson-3.9.5 rich-13.5.2 types-requests-2.31.0.2 types-urllib3-1.26.25.14\n"
     ]
    }
   ],
   "source": [
    "!pip install docarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "import openai\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# set up environment variables\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "OPENAI_API_BASE = os.environ['OPENAI_API_BASE']\n",
    "OPENAI_API_TYPE = os.environ['OPENAI_API_TYPE']\n",
    "OPENAI_API_VERSION = os.environ['OPENAI_API_VERSION']\n",
    "\n",
    "# set up OpenAI client\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "openai.api_base = OPENAI_API_BASE\n",
    "openai.api_type = OPENAI_API_TYPE\n",
    "openai.api_version = OPENAI_API_VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain for LLM App Development \n",
    "\n",
    "We talked about how building an LLM app involves doing some prompt management \n",
    "where we can either prepare the input data from the user with some \n",
    "pre-prompting, or do some post-prompting and some cleaning up after the LLM \n",
    "gives an output to ensure that our app performs the functionalities as expected.\n",
    "\n",
    "So, this kind of workflow usually involves a lot of abstractions where prompts \n",
    "are no longer static pieces of text, but dynamic, they have to integrate \n",
    "information.\n",
    "\n",
    "![](./images/Notebook_4-dynamic_prompt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dynamics requirement from a prompt will lead to the need for creating certain types of abstractions to properly handle and manage prompts effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another need in the context of more complex LLM App development, is the need for chaining prompts together, meaning connecting the output of one prompt to another. This is often the case for when prompts might be too large and a single call to the LLM won't be enough to solve the problem or the context window (maximum tokens/words the model can read and writer per request) is exceeded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/Notebook_4-prompt_chaining.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lanchain\n",
    "\n",
    "[Langchain](https://python.langchain.com/docs/get_started/introduction.html) is a framework created by Harrison Chase that facilitates the creation and management of dynamic prompts and chaining between prompts.\n",
    "\n",
    "Its main features are:\n",
    "- **Components**: abstractions for working with LMs\n",
    "- **Off-the-shelf chains**: assembly of components for accomplishing certain higher-level tasks\n",
    "\n",
    "With langchain it becomes much easier to create what are called Prompt Templates, which are prompts that can take in user data and abstract away the need for typing out everything that is required for a task to get done.\n",
    "\n",
    "Let's take a look at some simple examples to get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create an application with LangChain, we need to understand its core components:\n",
    "\n",
    "- Models\n",
    "- Prompts\n",
    "- Indexes\n",
    "- Chains\n",
    "- Agents (won't go into it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2023-08-17-14-48-39.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models**\n",
    "\n",
    "abstractions over the LLM APIs like the ChatGPT API.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! deployment_id is not default parameter.\n",
      "                    deployment_id was transferred to model_kwargs.\n",
      "                    Please confirm that deployment_id is what you intended.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(temperature=0, deployment_id=\"chatgpt-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can predict outputs from both LLMs and ChatModels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.predict(\"hi!\")\n",
    "# Output: \"Hi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the predict method over a string input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Snoozer'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"What would be a good name for a dog that loves to nap??\"\n",
    "\n",
    "\n",
    "chat_model.predict(text)\n",
    "# Output: \"Snuggles\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can use the `predict_messages` method over a list of messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Snoozer', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "text = \"What would be a good dog name for a dog that loves to nap?\"\n",
    "messages = [HumanMessage(content=text)]\n",
    "\n",
    "chat_model.predict_messages(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prompts**\n",
    "\n",
    "Prompt Templates are useful abstractions for reusing prompts. \n",
    "\n",
    "They are used to provide context for the specific task that the language model needs to complete. \n",
    "A simple example is a `PromptTemplate` that formats a string into a prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a good dog name for a dog that loves to nap?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"What is a good dog name for a dog that loves to {activity}?\")\n",
    "prompt.format(activity=\"nap\")\n",
    "# Output: \"What is a good dog name for a dog that loves to nap?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! deployment_id is not default parameter.\n",
      "                    deployment_id was transferred to model_kwargs.\n",
      "                    Please confirm that deployment_id is what you intended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ace'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=ChatOpenAI(deployment_id=\"chatgpt-4\"),\n",
    "    prompt=prompt,\n",
    ")\n",
    "chain.run(\"watch tennis on tv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create more complex ChatPromptTemplates that contains a list of ChatMessageTemplates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant that translates English to French.', additional_kwargs={}),\n",
       " HumanMessage(content='I love programming.', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "chat_prompt.format_messages(input_language=\"English\", output_language=\"French\", text=\"I love programming.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Parsers**\n",
    "\n",
    "OutputParsers convert the raw output from an LLM into a format that can be used downstream. Here is an example of an OutputParser that converts a comma-separated list into a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'bye']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "CommaSeparatedListOutputParser().parse(\"hi, bye\")\n",
    "# Output: ['hi', 'bye']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LLMChain**\n",
    "\n",
    "Finally, you can combine all these components into an LLMChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Golden Retriever',\n",
       " 'German Shepherd',\n",
       " 'Labrador Retriever',\n",
       " 'Beagle',\n",
       " 'Bulldog']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "template = \"\"\"You are a helpful assistant who generates comma separated lists.\n",
    "A user will pass in a category, and you should generated 5 objects in that category in a comma separated list.\n",
    "ONLY return a comma separated list, and nothing more.\"\"\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chain = LLMChain(\n",
    "    llm=ChatOpenAI(engine=\"chatgpt-4\"),\n",
    "    prompt=chat_prompt,\n",
    "    output_parser=CommaSeparatedListOutputParser()\n",
    ")\n",
    "chain.run(\"dogs\")\n",
    "# Output: ['Golden Retriever','Labrador Retriever','German Shepherd','Bulldog','Poodle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chain will take input variables, pass those to a prompt template to create a prompt, pass the prompt to an LLM, and then pass the output through an output parser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so these are the basics of langchain. But how can we leverage these abstraction capabilities inside our LLM app application?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the best applications of langchain is for the \"chat with your data\"-types of applications, where the user uploads a document like a pdf or a .txt file, and is able to query that document using langchain powered by an LLM like ChatGPT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Lab Exercises\n",
    "\n",
    "Let's take a look at a simple example of **Simple Sequential Chain**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    }
   ],
   "source": [
    "# This is an LLMChain to write a synopsis given a title of a play.\n",
    "llm = ChatOpenAI(temperature=.7, engine=\"chatgpt-4\")\n",
    "template = \"\"\"You are a learning assistant. Given a technical subject, write down 5 fundamental concepts to understand it.\n",
    "Subject: {subject}\n",
    "Learning assistant: The 5 fundamental concepts are:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"subject\"], template=template)\n",
    "learning_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an LLMChain to write a review of a play given a synopsis.\n",
    "#llm = ChatOpenAI(temperature=.7)\n",
    "template = \"\"\"You are an expert teacher in all technical and scientific fields. Given a list of 5 concepts, write down a simple intuitive explanation of each concept.\n",
    "Concepts:\n",
    "{concepts}\n",
    "Intuitive explanations:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"concepts\"], template=template)\n",
    "explanation_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the overall chain where we run these two chains in sequence.\n",
    "learning_overall_chain = SimpleSequentialChain(chains=[learning_chain, explanation_chain], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m1. Understanding of CAD (Computer-Aided Design): This involves the use of computer software to create 3D models. It's essential to know how to design or modify models for 3D printing.\n",
      "\n",
      "2. Knowledge of 3D Printing Technologies: Different printing technologies such as FDM (Fused Deposition Modeling), SLA (Stereolithography), and SLS (Selective Laser Sintering) are used for different applications. Understanding how they work is crucial.\n",
      "\n",
      "3. Materials Used in 3D Printing: Different materials such as plastics (ABS, PLA), metals, and ceramics are used in 3D printing. Knowing their properties and usage is important.\n",
      "\n",
      "4. Slicing: This is the process of converting a 3D model into hundreds or thousands of horizontal layers. The slicing software then instructs the 3D printer to follow this blueprint to create the object layer by layer.\n",
      "\n",
      "5. Post-Processing: After the printing process, the printed parts often need post-processing. This can include cleaning, support removal, surface finish, or other processes to achieve the desired final properties. Understanding these processes is key to achieving the best results.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m1. CAD (Computer-Aided Design): Imagine being a sculptor who is planning to make a sculpture. Instead of directly starting to chisel a stone, you decide to use a computer program to design your sculpture first. You can view it from all angles, make changes, and perfect your design before you even touch your stone. That's what CAD is - it's like your digital sketchpad where you can create, modify, and perfect your 3D model before you bring it into the real world through 3D printing.\n",
      "\n",
      "2. 3D Printing Technologies: Think of 3D printing technologies as different types of chefs. FDM is like a pastry chef who lays down layer after layer of dough to create a croissant. SLA is like a gourmet chef who uses a delicate process to create intricate dishes - it uses a laser to solidify liquid resin layer by layer. SLS, on the other hand, is like a barbecue master who uses high heat (a laser) to fuse together powder materials.\n",
      "\n",
      "3. Materials Used in 3D Printing: Just like how you choose different types of paper for sketching, painting, or crafting, you need to choose the right material for your 3D print. Plastics like ABS and PLA are common and versatile, kind of like your standard printer paper. Metals and ceramics are more specialized, like watercolor paper or cardstock, and are used for specific applications that need extra strength or heat resistance.\n",
      "\n",
      "4. Slicing: Imagine having a loaf of bread and you want to see what's inside without tearing it apart. So, you decide to slice it into thin pieces and look at each one. This is what slicing in 3D printing does. It slices your 3D model into thin layers and then tells the printer how to recreate each layer, one by one, until you have your whole 'loaf' or 3D model.\n",
      "\n",
      "5. Post-Processing: After baking a cake, you don't just serve it as is. You decorate it, maybe add some frosting, and make it look presentable. Similarly, after 3D printing an object it often needs some finishing touches. This might involve removing any support structures that helped it keep its shape during printing, smoothing out rough edges, or applying a finish to make it look its best.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"1. CAD (Computer-Aided Design): Imagine being a sculptor who is planning to make a sculpture. Instead of directly starting to chisel a stone, you decide to use a computer program to design your sculpture first. You can view it from all angles, make changes, and perfect your design before you even touch your stone. That's what CAD is - it's like your digital sketchpad where you can create, modify, and perfect your 3D model before you bring it into the real world through 3D printing.\\n\\n2. 3D Printing Technologies: Think of 3D printing technologies as different types of chefs. FDM is like a pastry chef who lays down layer after layer of dough to create a croissant. SLA is like a gourmet chef who uses a delicate process to create intricate dishes - it uses a laser to solidify liquid resin layer by layer. SLS, on the other hand, is like a barbecue master who uses high heat (a laser) to fuse together powder materials.\\n\\n3. Materials Used in 3D Printing: Just like how you choose different types of paper for sketching, painting, or crafting, you need to choose the right material for your 3D print. Plastics like ABS and PLA are common and versatile, kind of like your standard printer paper. Metals and ceramics are more specialized, like watercolor paper or cardstock, and are used for specific applications that need extra strength or heat resistance.\\n\\n4. Slicing: Imagine having a loaf of bread and you want to see what's inside without tearing it apart. So, you decide to slice it into thin pieces and look at each one. This is what slicing in 3D printing does. It slices your 3D model into thin layers and then tells the printer how to recreate each layer, one by one, until you have your whole 'loaf' or 3D model.\\n\\n5. Post-Processing: After baking a cake, you don't just serve it as is. You decorate it, maybe add some frosting, and make it look presentable. Similarly, after 3D printing an object it often needs some finishing touches. This might involve removing any support structures that helped it keep its shape during printing, smoothing out rough edges, or applying a finish to make it look its best.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = learning_overall_chain.run(\"3D printing\")\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sequential Chains**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an LLMChain to write a synopsis given a title of a play.\n",
    "# llm = ChatOpenAI(temperature=.7)\n",
    "template = \"\"\"You are a learning assistant. Given a technical subject, write down 5 fundamental concepts to understand it.\n",
    "Subject: {subject}\n",
    "Field: {field}\n",
    "Learning assistant: The 5 fundamental concepts are:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"subject\", \"field\"], template=template)\n",
    "learning_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"concepts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an LLMChain to write a review of a play given a synopsis.\n",
    "# llm = ChatOpenAI(temperature=.7)\n",
    "template = \"\"\"You are an expert teacher in all technical and scientific fields. Given a list of 5 concepts, write down a simple intuitive explanation of each concept.\n",
    "\n",
    "Concepts:\n",
    "{concepts}\n",
    "Intuitive explanations:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"concepts\"], template=template)\n",
    "explanation_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"explanations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the overall chain where we run these two chains in sequence.\n",
    "learning_overall_chain = SequentialChain(\n",
    "    chains=[learning_chain, explanation_chain],\n",
    "    input_variables=[\"subject\", \"field\"],\n",
    "    # Here we return multiple variables\n",
    "    output_variables=[\"concepts\", \"explanations\"],\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'subject': 'tennis',\n",
       " 'field': 'engineering',\n",
       " 'concepts': '1. Physics of Tennis: Understanding the physics involved in the sport, including the principles of force, motion, and energy transfer, which are crucial in serving, hitting, and returning the ball effectively.\\n\\n2. Material Science: Knowledge about different materials used in tennis equipment like racquets and balls and how their properties affect their performance. \\n\\n3. Aerodynamics: Understanding how the shape and spin of the ball can influence its trajectory and speed, and how these factors can be manipulated for strategic advantage.\\n\\n4. Biomechanics: Understanding the mechanics of the human body, particularly in relation to movement and exertion during a tennis match. This includes the study of muscle groups, force exerted, and injury prevention.\\n\\n5. Engineering Design: Knowledge about the engineering principles involved in designing and improving tennis equipment and facilities, such as racquets, courts, and training machines.',\n",
       " 'explanations': \"1. Physics of Tennis: This involves the study of how forces and motions work in the sport of tennis. Imagine swinging a tennis racket and hitting a ball; the way the ball flies off your racket and how far or fast it goes depends on the amount of force you put into your swing and the direction of your swing. This force and the resulting motion of the ball are all governed by the laws of physics, which also dictate how the energy from your swing is transferred to the ball.\\n\\n2. Material Science: This is like understanding the ingredients in a recipe - the materials that make up the tennis racquets and balls. For instance, the type of strings used in a racquet can affect how much power or control a player has. Similarly, the material used to make a tennis ball can influence how high it bounces or how fast it travels. \\n\\n3. Aerodynamics: This is the science of how air moves around objects. In tennis, a ball's shape and spin can change its path and speed. Imagine throwing a tennis ball with a spin - you'll notice it doesn't just travel straight but curves in the air. The way the air interacts with the spinning ball influences this curve, which players can use to their advantage in a match.\\n\\n4. Biomechanics: This is the study of how the human body moves and works, especially when playing sports like tennis. It's like being a mechanic, but instead of cars, you're studying human bodies. This field helps us understand which muscles are used when serving a ball, how to minimize injury risks, and even how to improve performance in the game.\\n\\n5. Engineering Design: This involves applying scientific and engineering principles to design and improve tennis gear and venues. Think of it as the architecture and engineering behind creating a great tennis racquet or designing a tennis court. It's about making sure the racquet is light but sturdy, the court provides the right bounce, and even that the ball machines work effectively for practice.\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_overall_chain({\"subject\":\"tennis\", \"field\": \"engineering\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Q&A Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install docarray\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Superhero Name</th>\n",
       "      <th>Superpower</th>\n",
       "      <th>Power Level</th>\n",
       "      <th>Catchphrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Captain Thunder</td>\n",
       "      <td>Bolt Manipulation</td>\n",
       "      <td>90</td>\n",
       "      <td>Feel the power of the storm!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Silver Falcon</td>\n",
       "      <td>Flight and Agility</td>\n",
       "      <td>85</td>\n",
       "      <td>Soar high, fearlessly!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mystic Shadow</td>\n",
       "      <td>Invisibility and Illusions</td>\n",
       "      <td>78</td>\n",
       "      <td>Disappear into the darkness!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blaze Runner</td>\n",
       "      <td>Pyrokinesis</td>\n",
       "      <td>88</td>\n",
       "      <td>Burn bright and fierce!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Electra-Wave</td>\n",
       "      <td>Electric Manipulation</td>\n",
       "      <td>82</td>\n",
       "      <td>Unleash the electric waves!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Superhero Name                  Superpower  Power Level  \\\n",
       "0  Captain Thunder           Bolt Manipulation           90   \n",
       "1    Silver Falcon          Flight and Agility           85   \n",
       "2    Mystic Shadow  Invisibility and Illusions           78   \n",
       "3     Blaze Runner                 Pyrokinesis           88   \n",
       "4     Electra-Wave       Electric Manipulation           82   \n",
       "\n",
       "                    Catchphrase  \n",
       "0  Feel the power of the storm!  \n",
       "1        Soar high, fearlessly!  \n",
       "2  Disappear into the darkness!  \n",
       "3       Burn bright and fierce!  \n",
       "4   Unleash the electric waves!  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./superheroes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'superheroes.csv'\n",
    "loader = CSVLoader(file_path=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's set up our Vector store (we'll talk about what that is in a second):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(vectorstore_cls=DocArrayInMemorySearch).from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Tell me the catch phrase for Captain Thunder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " Captain Thunder's catchphrase is \"Feel the power of the storm!\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, cool! So, now let's backtrack a little bit and discuss what is going on.\n",
    "\n",
    "If we want LLMs to get access to our data in order to help us get insights, we have one major problem: LLMs have a limited context window, meaning they can only process a few thousand words at a time which constraints their ability to answer questions (for example) of really big documents. \n",
    "\n",
    "That's where things like embeddings and vector stores come into play, these are way of representing the data in such a way to facilitate the access by an LLM. Let's break it down, starting with embeddings:\n",
    "\n",
    "Embeddings are numerical representations of data, meaning, their a way to represent data such that the semantic information of that data is properly reflected in the distances between the data points in the embedding.\n",
    "\n",
    "That means that text with similar content will have similar vectors (which is a way of saying that they'll be closer together in the embedding)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2023-07-30-19-29-27.png)\n",
    "\n",
    "[LangChain for LLM Application Development by Deeplearning.ai](https://learn.deeplearning.ai/langchain/lesson/1/introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's talk about vector databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vector database is a way to store these embeddings, these numerical representations that we just discussed.\n",
    "\n",
    "The pipeline is:\n",
    "- In coming document\n",
    "- Create chunks of text from that document\n",
    "- Embed each chunk\n",
    "- Store these embeddings\n",
    "\n",
    "![](2023-07-30-19-32-13.png)\n",
    "\n",
    "[LangChain for LLM Application Development by Deeplearning.ai](https://learn.deeplearning.ai/langchain/lesson/1/introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can query those embeddings stored in the vector database to get the most relevant responses!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So when we create a query, that query is first embedded and then we compare its embedding with the embeddings we have stored in the vector database. We then select the N-most similar embeddings, and pass those to the LLM.\n",
    "\n",
    "![](images/2023-07-30-19-34-48.png)\n",
    "\n",
    "[LangChain for LLM Application Development by Deeplearning.ai](https://learn.deeplearning.ai/langchain/lesson/1/introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Embedding__: the useful data representation that will be used as the thing (or things) we can query\n",
    "- __Vector Database__: the vectorization of the embedding chunks (the database for the embeddings where we can do the query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "\n",
    "\n",
    "![](./images/embeddings.png)\n",
    "\n",
    "![](./images/embeddings2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Database\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![](./images/2023-07-17-12-48-28.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- https://python.langchain.com/docs/get_started/introduction.html\n",
    "- https://medium.com/@remitoffoli/a-visual-guide-to-llm-powered-app-architecture-57e47426a92f\n",
    "- [LangChain for LLM App Development short course by coursera](https://learn.deeplearning.ai/langchain/lesson/5/question-and-answer)\n",
    "- [LLM Evaluation](https://learn.deeplearning.ai/langchain/lesson/6/evaluation)\n",
    "[Models, Prompts, parsers, memory and chains from this langchain for](https://learn.deeplearning.ai/langchain/lesson/7/agents)\n",
    "- [Chat With Your Data - Retrieval](https://learn.deeplearning.ai/langchain-chat-with-your-data/lesson/5/retrieval)\n",
    "- [Emebeddings simple definition](https://learn.deeplearning.ai/langchain/lesson/5/question-and-answer)\n",
    "- [Vector DBs - simple definition](https://learn.deeplearning.ai/langchain/lesson/5/question-and-answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
